stage_1:
  model: da3
  rae:
    target: 
    params:
      encoder_cls: 
      encoder_config_path: 
      encoder_input_size: 
      encoder_params: 
      decoder_config_path: 
      pretrained_decoder_path: 
      noise_tau: 
      reshape_to_2d: 
      normalization_stat_path: 
  da3:
    ckpt: depth-anything/DA3-GIANT-1.1
  vggt:
    ckpt: facebook/VGGT-1B


stage_2:
  model: DiTwDDTHeadMVRM
  target: stage2.models.DDT_MVRM.DiTwDDTHeadMVRM
  params:
    input_size: [27, 36]  # feat_H, feat_W
    patch_size: 1
    in_channels: 1536
    hidden_size: [1536, 3072]
    depth: [28, 2]
    num_heads: [16, 16]
    mlp_ratio: 4.0
    class_dropout_prob: 0.1
    num_classes: 
    use_qknorm: true 
    use_swiglu: true
    use_rope: true
    use_rmsnorm: true
    wo_shift: false
    use_pos_embed: true
  ckpt: 


transport:
  params:
    path_type: 'Linear'
    prediction: 'velocity'
    loss_weight: null
    time_dist_type: 'logit-normal_0_1'


sampler:
  mode: ODE
  params:
    sampling_method: 'euler'
    num_steps: 50
    atol: 1.0e-6
    rtol: 1.0e-3
    reverse: false


guidance:
  method: 'cfg'
  scale: 1.0
  t_min: 0.0
  t_max: 1.0


misc:
  latent_size: [1, 973, 1536] 
  num_classes: 
  time_dist_shift_dim: 1492992  
  time_dist_shift_base: 4096


training:
  global_seed: 42
  precision: fp32
  
  
  
  # --------------------------------- JIHYE -----------------------------------------
  # 아래 내용 수정 주시면 될 것 같습니다
  # 일단 20 에폭으로 돌려보고, global_batch_size, grad_accum_steps를 조정해보면 될 것 같아요 
  # global_batch_size가 뭔지 조금 헷갈릴 수 있어서 부연 설명 드리겠습니다
  # 공식: global_batch_size = tot_num_gpu * batch_per_gpu * grad_accum
  # 만약 8대 gpu에서, 한 gpu당 bs=2, grad_accum=4를 하고 싶으면
  # 먼저 grad_accum_steps = 4 를 먼저 설정하시고, global_batch_size는 아래로 맞춰주시면 됩니다. 
  # global_batch_size = 8(tot_gpu_num) * 2(bs per gpu) * 4(grad_accum) = 64 로 설정하기
  epochs: 20
  grad_accum_steps: 4
  global_batch_size: 64     # 8(gpu8대) * 2(한 gpu bs) * 4(grad_accum)
  num_workers: 32           # 4 * gpu개수 로 설정해주세요
  # ---------------------------------------------------------------------------------


  ema_decay: 0.9995
  shuffle: True
  log_interval: 1



  # --------------------------------- JIHYE -----------------------------------------
  # ckpt 저장 step을 일단 10k로 설정했습니다
  ckpt_step_interval: 10000
  # ---------------------------------------------------------------------------------
  


  sample: False
  sample_every: 2000  
  clip_grad: 1.0
  optimizer:
    lr: 2.0e-4
    betas: [0.9, 0.95]
    weight_decay: 0.0
  scheduler:
    type: linear
    warmup_epochs: 10
    decay_end_epoch: 20
    base_lr: 2e-4
    final_lr: 2e-5
    warmup_from_zero: false


log:
  # --------------------------------- JIHYE -----------------------------------------
  # ckpt와 log 저장 directory
  result_root_dir: result_train/stage2/jihye
  # ---------------------------------------------------------------------------------
  tracker:
    name:  
    wandb:
      key: 
      entity: 
      project: 
      msg:

data:
  train:
    image_size: 512 
    num_input_view: 1
    list: [hypersim]
    hypersim:
      # --------------------------------- JIHYE -----------------------------------------
      # hypersim dataset path 설정
      ann_path: metadata_images_split_scene_v1.csv                
      hq_root_path: /mnt/dataset1/MV_Restoration/hypersim    # hypersim 데이터셋 경로 설정해주세요
      # ---------------------------------------------------------------------------------
      view_sel_strategy:
    tartanair:
      ann_path: 
      hq_root_path: 
      view_sel_strategy:
  val:
    image_size:  
    num_input_view: 
    list:
    hypersim:
      num_eval_img: 
      ann_path: 
      hq_root_path: 
      view_sel_strategy:    
    tartanair:
      num_eval_img: 
      ann_path: 
      hq_root_path: 
      view_sel_strategy:
  

mvrm:
  input_img: lq               
  lq_latent_cond: addition    
  train:
    extract_feat_layers: [17]
    concat_feat: False
  val:
    restore_feat_layers: [17]
    concat_feat: False 
    
